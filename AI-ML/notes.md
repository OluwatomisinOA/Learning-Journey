## WHAT IS Artificial Intelligence?

- Artificial Intelligence is the branch of Computer Science that is focused on creating systems that perform tasks that would be normally required by Human Intelligence. These tasks can range understanding of: natural language, recognizing patterns, making decisions, learning from experience.

# History of AI

- Greek Mythology - Talos
  Talos was a giant animated bronze warrior programmed to guard the island of Crete created by Hephaestus.

- In 1950, Alan Turing published a landmark paper in which he speculated about the possibility pf creating machines that think.

- 1951 - Game AI
  Christopher Strachey wrote a checkers program and Dietrich Prinz wrote one for chess.

- 1956 - The Birth of AI
  John McCarthy first coined the term "Artificial Intelligence" in 1956 at Dartmouth Conference. He also defined AI as the "science and engineering of making intelligent machines".

- 1959 - First AI Laboratory
  MIT AI lab was first set up in 1959. The research of AI began.

- 1960 - General Motors Robot
  First robot was introduced to General Motors assembly line.

- 1961 - First Chatbot
  The first AI Chatbot called ELIZA was creted in 1961.

- 1997 - IBM's Deep Blue
  IBM's Deep Blue beats world champion Garry Kasporov in the game of chess.

- 2005 - DARPA Grand Challenge
  Stanford Racing Team's autonomous robotic car, Stanley wins 2005 DARPA Grand Challenge.

- 2011 - IBM Watson
  IBM's question answering system, Watson, defeated the two greatest; copardyl champions, Brad Rutter and Ken Jennings.

## What is AI?

- AI is the development of computer systems that are capable of performing tasks that normally require human intelligenc, such as decision making, object detention, solving complex problems and so on.

# Main Features of AI

- Decision Making
- Solve Complex Problems
- Perform High Level Computation
- Increased Accuracy

## STAGES OF AI

- Artificial Narrow Intelligence (ANI):
  also known as Weak AI, ANI is the stage of AI involving machines that can perform only a narrowly defined set of specific tasks. E.g. Siri, Alexi, Alphago etc.

- Artificial General Intelligence (AGI):
  also known as Strong AI, AGI is the stage in the evolution of AI where machines will possess the ability to think and make decisions like humans.

- Artificial Super Intelligence (ASI):
  is the stage of AI where the capability of computers will surpass human beings.

## TYPES OF AI

- Reactive Machine AI:
  includes machine that solely operate based on the prsesnt data, taking into account only the current situation. Reactive AI Machines cannot form inferences from the data to evaluate their future actions. E.g. IBM's Deep Blue.

- Limited Memory AI:
  can make informed improved decisions by studying the past data from its memory. Such an AI has a short lived or a temporary memory that can be used to store past experiences and hence evaluate future actions. Self driving cars uses data collected in the recent past to make immediate decisions.

- Theory of Mind AI:
  mainly on emotional intelligence, so that human believes and thought can be better comprehended. It is speculated to play a major role in human psychology.

- Self Aware AI:
  include machines that have their own consciousness and become self aware.

## DOMAINS OF AI

- Machine Learning:
  is the science of getting machines to interpret, process and analyze data in order to solve real world problems.

- Deep Learning:
  (or Neural Networks), is the process of implementing neural networks onhigh dimensional data to gain insights and form solutions. It is the logic behind the face verification on Facebook, self-driving cars, virtual assistants like Siri & Alexi.

- Natural Language Processing:
  is the science of drawing insights from natural human language in order to communicate with machines and grow businesses. E.g. Twitter, which uses NLP to filter out terroristic languages in their tweets and Amazon, which uses NLP to understand customer reviews & improves user experience.

- Robotics:
  is the branch of AI that focuses on diffirent branches of & applications of robots. E.g. Sophia

- Fuzzy Logic:
  is a computing approach that is based on the principle of degree of truth instead of modern logic that we use which is basically the boolean logic. It is used in medical fields to solve complex problems which involves decision making. It is also used in automating gear systems in cars.

- Expert Systems:
  is an AI system that learns and reciprocates the decision-making ability of a human expert. It uses if then logic notions in order to solve any complex problem. They are mainly used in information managements. They are seen to be used in fraud detection, virus detection, also in managing medical and hospital records etc.

# AI vs Machine Learning vs Deep Learning

# Why ML was introduced?

- Statistics: how to efficiently train large comples models?
- Computer Sciences and AI: how to train more robust versions of the AI systems?
- Neuroscience: how to design operational models of the brain?

## PYTHON FOR AI

# Python Packages for AI

- Tensorflow:
  Tensorflow library was developed by Google in collaboration with Brain Team. It is popularly used in writing machine learning algorithms.

Features of Tensorflow:
(i) Responsive construct
(ii) Flexible
(iii) Easily trainable
(iv) Parallel neural network training

- Scikit-Learn:
  is a pyhon library associated with Numpy & Scipy. It is considered as one of the best libraries for working with complex data.

Features:
(i) Cross validation
(ii) Unsupervised learning algorithms
(iii) Feature extraction

- Numpy:
  is a python library mainly used for computing scientific/mathematical data.

Features:
(i) Supports multidimensional array
(ii) Numerical Analysis
(iii) Intuitive

- Theano:
  ia a python library that allows you to define, optimize and evaluate mathematical expressions involving multidimensional array efficiently.
  You can't fit Theano into production environments.

Features:
(i) Tight integration with Numpy
(ii) Transparent use of a GPU
(iii) Estimate unit testing & self verification.

- Keras:
  simplifies the implementation of neural networks. It also provides some of the test utilites for compiling models, processing dataset, visualization of graphs, and much more.

Features:
(i) Runs smoothly on both CPU & GPU
(ii) Support all types of neural networks
(iii) Completely pyhton based

- Natural Language Analysis with NLTK:
  The Natural Language Tool Kit is an open source python library for Natural Language Processing, Text Analysis & Text Mining.

Features:
(i) Study natural language text
(ii) Text analysis
(iii) Sentimental Analysis

## INTRO TO AI

# Demand of AI

- More Computational Power
- More Data
- Better Algorithms
- Broad Investment

# What is AI?

The THeory & development of computer systems able to perorm tasks normally requiring human intelligence, such as virtual perceptions, speech recognitions, decision making & translation between languages.

# Domains

- Machine Learning
- Natural Language Processing
- Knowledge Base
- Deep Learning
- Computer Vision
- Expert Systems

## INTRO TO ML

# What is ML?

in simple terms, ML is a subset of AI which provides machines the ability to learn automatically and improve from experience without being explicitly programmed.

# Machine Learning Process

It involves building a 'predictive model' that can be used to find a 'solution' for a 'problem statement'.

- A well defined machine kearning process must have these 7 steps:
  (i) Define Objective
  (ii) Data Gathering
  (iii) Preparing Data
  (iv) Data Exploration / EDA
  (v) Building a Model
  (vi) Model Evaluation
  (vii) Predictions

# Problem 1: Weather Forecast using ML

- Step 1: Define the objective of the problem
  To predict the possibility of rain by studying waether conditions.
  It is essential to take notes on what of type of data can be used to solve this problems.
  Questions:

  > What are we trying to predict?
  > What are the target features?
  > What is the input data?
  > What kind of pattern are we facing? binary classification? clustering?

- Step 2: Data gathering
  Data such as weather conditions, humidity level, temperature, pressure etc. are either collected manually or scarped from the web.

- Step 3: Preparing Data

  > Transform data into desired formats
  > Data cleaning: missing values, corrupted data, remove unnecessary data.

- Step 4: EDA
  Data exploration involves understanding the patterns and trends in the data. At this stage, all the useful insights are drawn and correlations between the variables are understood.

- Step 5: Building a ML Model
  At this stage a predictive model is built by using ML algorithms such as Linear Regression, Decision Trees etc.

  > ML is built by using the trainig the dataset
  > The model is the ML algorithm that preidcts the output by using the data fed to it.

- Step 6: Model Evaluation & Optimization
  The efficiency of the model is evaluated and any further improvement in the model is implemented.

  > Machine learning model is evaluated by using the testing dataset.
  > The accuracy of the model is calculated.
  > Further improvements are done bu using techniques like Parameter tuning.

- Step 7: Predictions
  The final outcome is predicted after performing parameter tuning & improving the accuracy of the model.

# Types of ML

- Supervised Learning:
  is a technique in which we teach or train the machine using data that is well labelled.
  Labelled data > Data cleaning > EDA > Algorithm > Model Evaluation > Labelled output

- Unsupervised Learning:
  is the training of the machine using information that is unlabelled and allow the algorithm to act on the information without guidance.
  Unlabelled data > Data cleaning > EDA > Algorithm > Model evaluation > Unlabelled.

- Reinforcement Learning:
  is a part of machine learning where an agent is put in an environment and he learns to behave in the environment by performing certain actions and observing the rewards which it gets from those actions.

# Machine Learning Algorithms